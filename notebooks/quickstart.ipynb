{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6becd0",
   "metadata": {},
   "source": [
    "# CaptionQA Quickstart\n",
    "\n",
    "Welcome to the CaptionQA quickstart notebook. This guide helps you verify your development environment, explore the dataset utilities bundled with the repository, and establish a baseline workflow for panoramic captioning + QA research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcec78cb",
   "metadata": {},
   "source": [
    "## 1. Environment setup\n",
    "\n",
    "CaptionQA uses [uv](https://docs.astral.sh/uv/) for dependency management and targets Python 3.10+. On Windows 11 PowerShell, the recommended bootstrap sequence is:\n",
    "\n",
    "```powershell\n",
    "winget install --id Astral.Uv -e\n",
    "uv venv captionqa\n",
    ".\\captionqa\\Scripts\\Activate.ps1\n",
    "uv pip install --editable .\n",
    "```\n",
    "\n",
    "If you are working on macOS or Linux, the commands are identical except for the activation step (`source captionqa/bin/activate`).\n",
    "\n",
    "> **Tip:** Ensure that FFmpeg is installed and available on your `PATH` before attempting to process audio/video assets.\n",
    "\n",
    "Run the following cell to confirm the Python version and virtual environment information inside the notebook kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca2fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "print(f'Python version: {sys.version.split()[0]}')\n",
    "print(f'Executable: {sys.executable}')\n",
    "print(f'Platform: {platform.platform()}')\n",
    "print(f'Virtual env: {os.environ.get(\"VIRTUAL_ENV\", \"<none>\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c0de5",
   "metadata": {},
   "source": [
    "If the `Virtual env` field shows `<none>`, activate the `captionqa` environment (or your preferred venv) and restart the Jupyter kernel before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa61a14",
   "metadata": {},
   "source": [
    "## 2. Repository paths\n",
    "\n",
    "The repository expects a `datasets/` directory in the project root. On Windows, the default clone uses a symbolic link that points to `D:/CaptionQA/data`. If you are running inside WSL or a containerized environment, update the link to a valid location or replace it with a regular directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd().resolve()\n",
    "datasets_dir = repo_root / 'datasets'\n",
    "\n",
    "print(f'Repository root: {repo_root}')\n",
    "print(f'datasets/ exists: {datasets_dir.exists()}')\n",
    "if datasets_dir.exists():\n",
    "    print(f'datasets/ points to: {datasets_dir.resolve()}')\n",
    "else:\n",
    "    print('datasets/ directory is missing. Create it or update the symlink before downloading datasets.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a7a856",
   "metadata": {},
   "source": [
    "If the dataset path is missing or points to an inaccessible drive, create a directory that suits your platform, for example:\n",
    "\n",
    "```powershell\n",
    "# Windows PowerShell\n",
    "Remove-Item datasets\n",
    "New-Item -ItemType Directory -Path datasets\n",
    "```\n",
    "\n",
    "```bash\n",
    "# macOS / Linux\n",
    "rm -rf datasets\n",
    "mkdir -p datasets\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9ad98",
   "metadata": {},
   "source": [
    "## 3. Dataset utilities\n",
    "\n",
    "The `data.download` module centralizes dataset metadata and provides a command-line interface. The next cell lists all datasets currently configured. This is a safe operation that does **not** download any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bcfa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.download import DATASETS\n",
    "\n",
    "for name, task in DATASETS.items():\n",
    "    print('{:<10s} - {}'.format(name, task.description))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d369b10",
   "metadata": {},
   "source": [
    "Use the CLI from a terminal to download assets once you have granted Hugging Face access where required:\n",
    "\n",
    "```bash\n",
    "python -m data.download --list\n",
    "python -m data.download 360x --output datasets --dry-run\n",
    "python -m data.download leader360v --output datasets\n",
    "```\n",
    "\n",
    "The `--dry-run` option prints the operations without performing any downloads, which is useful for verifying credentials and paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d8835",
   "metadata": {},
   "source": [
    "## 4. Inspecting a downloaded dataset\n",
    "\n",
    "After downloading, you can explore the file structure programmatically. The example below demonstrates how to enumerate the top-level contents of the 360x dataset. If the dataset is not yet downloaded, the code will notify you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e97f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "hr_root = datasets_dir / '360x' / '360x_dataset_HR'\n",
    "if hr_root.exists():\n",
    "    entries = sorted(hr_root.iterdir())\n",
    "    print(f'Found {len(entries)} items under {hr_root}:')\n",
    "    for path in islice(entries, 10):\n",
    "        print(' -', path.relative_to(hr_root))\n",
    "    if len(entries) > 10:\n",
    "        print('...')\n",
    "else:\n",
    "    print('360x high-resolution dataset not found. Run the downloader once you have access.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea23f79b",
   "metadata": {},
   "source": [
    "Repeat the pattern for other datasetsâ€”adjust the root path and traversal depth depending on the structure (archives vs. Git repositories)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be30e56",
   "metadata": {},
   "source": [
    "## 5. Next steps\n",
    "\n",
    "* Prototype captioning models using your framework of choice (e.g., PyTorch + Hugging Face Transformers).\n",
    "* Ingest panoramic video clips and convert them into frame sequences or features suitable for model training.\n",
    "* Integrate QA annotations by aligning temporal segments with generated captions.\n",
    "\n",
    "This notebook will continue to evolve as the project matures. Feel free to add exploratory experiments, preprocessing utilities, and evaluation routines in subsequent sections."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
