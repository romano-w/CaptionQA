{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6becd0",
   "metadata": {},
   "source": [
    "# CaptionQA Quickstart\n",
    "\n",
    "Welcome to the CaptionQA quickstart notebook. This guide helps you verify your development environment, explore the dataset utilities bundled with the repository, and establish a baseline workflow for panoramic captioning + QA research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcec78cb",
   "metadata": {},
   "source": [
    "## 1. Environment setup\n",
    "\n",
    "CaptionQA uses [uv](https://docs.astral.sh/uv/) for dependency management and targets Python 3.10+. On Windows 11 PowerShell, the recommended bootstrap sequence is:\n",
    "\n",
    "```powershell\n",
    "winget install --id Astral.Uv -e\n",
    "uv venv captionqa\n",
    ".\\captionqa\\Scripts\\Activate.ps1\n",
    "uv pip install --editable .\n",
    "```\n",
    "\n",
    "If you are working on macOS or Linux, the commands are identical except for the activation step (`source captionqa/bin/activate`).\n",
    "\n",
    "> **Tip:** Ensure that FFmpeg is installed and available on your `PATH` before attempting to process audio/video assets.\n",
    "\n",
    "Run the following cell to confirm the Python version and virtual environment information inside the notebook kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ca2fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.1\n",
      "Executable: c:\\Users\\willj\\Documents\\Coding Projects\\CaptionQA\\captionqa\\Scripts\\python.exe\n",
      "Platform: Windows-10-10.0.26100-SP0\n",
      "Virtual env: C:\\Users\\willj\\Documents\\Coding Projects\\CaptionQA\\captionqa\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "print(f'Python version: {sys.version.split()[0]}')\n",
    "print(f'Executable: {sys.executable}')\n",
    "print(f'Platform: {platform.platform()}')\n",
    "print(f'Virtual env: {os.environ.get(\"VIRTUAL_ENV\", \"<none>\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c0de5",
   "metadata": {},
   "source": [
    "If the `Virtual env` field shows `<none>`, activate the `captionqa` environment (or your preferred venv) and restart the Jupyter kernel before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9ad98",
   "metadata": {},
   "source": [
    "## 2. Dataset utilities\n",
    "\n",
    "The `captionqa.data.download` module centralizes dataset metadata and provides a command-line interface. The next cell lists all datasets currently configured. This is a safe operation that does **not** download any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80bcfa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset root: D:\\CaptionQA\\data\n",
      "\n",
      "Available datasets:\n",
      "360x       - Panoramic video dataset with scene descriptions, action labels, and binaural audio.\n",
      "360dvd     - Dense 360° video understanding dataset for video-language modeling.\n",
      "leader360v - Large-scale 360° dataset for object tracking and viewpoint-aware understanding.\n",
      "360sr      - Static panoramic scene classification dataset for spatial scene context models.\n",
      "avqa       - Audio-visual question answering dataset repository with preprocessing utilities.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from captionqa.data import DATASETS\n",
    "\n",
    "# Resolve the dataset root to the repository-level 'datasets' directory by default.\n",
    "# Priority: 1) CAPTIONQA_DATASETS env var  2) repo root discovery  3) current cwd fallback\n",
    "env_root = os.environ.get('CAPTIONQA_DATASETS')\n",
    "if env_root:\n",
    "    DATASET_ROOT = Path(env_root).expanduser().resolve()\n",
    "else:\n",
    "    cwd = Path.cwd()\n",
    "    repo_root = None\n",
    "    for p in [cwd, *cwd.parents]:\n",
    "        if (p / 'pyproject.toml').exists() or (p / '.git').exists():\n",
    "            repo_root = p\n",
    "            break\n",
    "    DATASET_ROOT = ((repo_root or cwd) / 'datasets').resolve()\n",
    "\n",
    "print(f'Dataset root: {DATASET_ROOT}')\n",
    "print('\\nAvailable datasets:')\n",
    "for name, task in DATASETS.items():\n",
    "    print(f'{name:<10s} - {task.description}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d369b10",
   "metadata": {},
   "source": [
    "Use the CLI from a terminal to download assets once you have granted Hugging Face access where required:\n",
    "\n",
    "```bash\n",
    "python -m captionqa.data.download --list\n",
    "python -m captionqa.data.download 360x --output datasets --dry-run\n",
    "python -m captionqa.data.download leader360v --output datasets\n",
    "```\n",
    "\n",
    "The `--dry-run` option prints the operations without performing any downloads, which is useful for verifying credentials and paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d8835",
   "metadata": {},
   "source": [
    "## 3. Inspecting a downloaded dataset\n",
    "\n",
    "After downloading, you can explore the file structure programmatically. The example below demonstrates how to enumerate the top-level contents of the 360x dataset. If the dataset is not yet downloaded, the code will notify you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8e97f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset root: D:\\CaptionQA\\data\n",
      "Found 5 items under D:\\CaptionQA\\data\\360x\\360x_dataset_HR:\n",
      " - .cache\n",
      " - .gitattributes\n",
      " - binocular\n",
      " - README.md\n",
      " - TAL_annotations\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Resolve dataset root in this priority order:\n",
    "# 1) DATASET_ROOT defined earlier in the notebook\n",
    "# 2) CAPTIONQA_DATASETS environment variable (e.g., set to D:\\CaptionQA\\data)\n",
    "# 3) 'datasets' at the repository root (walk up to find pyproject.toml/.git)\n",
    "dataset_root = globals().get('DATASET_ROOT')\n",
    "if dataset_root is None:\n",
    "    env_root = os.environ.get('CAPTIONQA_DATASETS')\n",
    "    if env_root:\n",
    "        dataset_root = Path(env_root).expanduser().resolve()\n",
    "    else:\n",
    "        cwd = Path.cwd()\n",
    "        repo_root = None\n",
    "        for p in [cwd, *cwd.parents]:\n",
    "            if (p / 'pyproject.toml').exists() or (p / '.git').exists():\n",
    "                repo_root = p\n",
    "                break\n",
    "        dataset_root = ((repo_root or cwd) / 'datasets').resolve()\n",
    "\n",
    "print(f'Using dataset root: {dataset_root}')\n",
    "\n",
    "hr_root = dataset_root / '360x' / '360x_dataset_HR'\n",
    "if hr_root.exists():\n",
    "    entries = sorted(hr_root.iterdir())\n",
    "    print(f'Found {len(entries)} items under {hr_root}:')\n",
    "    for path in islice(entries, 10):\n",
    "        print(' -', path.relative_to(hr_root))\n",
    "    if len(entries) > 10:\n",
    "        print('...')\n",
    "else:\n",
    "    print(f'360x high-resolution dataset not found at {hr_root}. If you have access, run:')\n",
    "    print('  python -m captionqa.data.download 360x --output', dataset_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea23f79b",
   "metadata": {},
   "source": [
    "Repeat the pattern for other datasets—adjust the root path and traversal depth depending on the structure (archives vs. Git repositories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3276f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "360dvd root: D:\\CaptionQA\\data\\360dvd\n",
      "Found 1 items under D:\\CaptionQA\\data\\360dvd:\n",
      " - 360DVD_dataset.zip\n",
      "\n",
      "leader360v root: D:\\CaptionQA\\data\\leader360v\\Leader360V\n",
      "Found 8 items under D:\\CaptionQA\\data\\leader360v\\Leader360V:\n",
      " - .cache\n",
      " - .gitattributes\n",
      " - assets\n",
      " - README.md\n",
      " - Sample1\n",
      " - Sample2\n",
      " - Sample3\n",
      " - Sample4\n",
      "\n",
      "360sr root: D:\\CaptionQA\\data\\360sr\\360SR-Challenge\n",
      "Found 5 items under D:\\CaptionQA\\data\\360sr\\360SR-Challenge:\n",
      " - 360SR Challenge Results -- Video.xlsx\n",
      " - archives\n",
      " - NTIRE 2023_ 360° Omnidirectional Super Resolution - Track 1 Image.xlsx\n",
      " - Ntire2023-Flickr360\n",
      " - Ntire2023-ODV360\n",
      "\n",
      "avqa root: D:\\CaptionQA\\data\\avqa\\AVQA\n",
      "Found 7 items under D:\\CaptionQA\\data\\avqa\\AVQA:\n",
      " - .git\n",
      " - .gitignore\n",
      " - data\n",
      " - HAVF\n",
      " - pics\n",
      " - preprocess\n",
      " - README.md\n"
     ]
    }
   ],
   "source": [
    "# Resolve dataset root (reuse prior logic)\n",
    "dataset_root = globals().get('DATASET_ROOT')\n",
    "if dataset_root is None:\n",
    "    env_root = os.environ.get('CAPTIONQA_DATASETS')\n",
    "    if env_root:\n",
    "        dataset_root = Path(env_root).expanduser().resolve()\n",
    "    else:\n",
    "        cwd = Path.cwd()\n",
    "        repo_root = None\n",
    "        for p in [cwd, *cwd.parents]:\n",
    "            if (p / 'pyproject.toml').exists() or (p / '.git').exists():\n",
    "                repo_root = p\n",
    "                break\n",
    "        dataset_root = ((repo_root or cwd) / 'datasets').resolve()\n",
    "\n",
    "def show_dir(root: Path, name: str, limit: int = 10):\n",
    "    print(f'\\n{name} root: {root}')\n",
    "    if not root.exists():\n",
    "        print(f'[missing] {name} not found. If you have access, run:')\n",
    "        print('  python -m captionqa.data.download', name.lower(), '--output', dataset_root)\n",
    "        return\n",
    "    entries = sorted(root.iterdir())\n",
    "    print(f'Found {len(entries)} items under {root}:')\n",
    "    for path in islice(entries, limit):\n",
    "        print(' -', path.name)\n",
    "    if len(entries) > limit:\n",
    "        print('...')\n",
    "\n",
    "# 360DVD (archive extracted into the dataset directory)\n",
    "dvd_root = dataset_root / '360dvd'\n",
    "show_dir(dvd_root, '360dvd')\n",
    "\n",
    "# Leader360V (HF snapshot under Leader360V subfolder)\n",
    "leader_root = dataset_root / 'leader360v' / 'Leader360V'\n",
    "show_dir(leader_root, 'leader360v')\n",
    "\n",
    "# 360SR (Google Drive folder under 360SR-Challenge)\n",
    "sr_root = dataset_root / '360sr' / '360SR-Challenge'\n",
    "show_dir(sr_root, '360sr')\n",
    "\n",
    "# AVQA (git repo under AVQA folder)\n",
    "avqa_root = dataset_root / 'avqa' / 'AVQA'\n",
    "show_dir(avqa_root, 'avqa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0396b9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "captionqa (3.10.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
