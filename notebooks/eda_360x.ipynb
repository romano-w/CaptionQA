{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05ba053",
   "metadata": {},
   "source": [
    "# **360x Dataset EDA**\n",
    "\n",
    "Quick exploratory checks on the 360x panoramic dataset: verify structure, inspect sample entries, and capture basic summary stats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59231e7",
   "metadata": {},
   "source": [
    "## 1. Resolve dataset root\n",
    "\n",
    "Uses the same resolution logic as the quickstart notebook: prefer `CAPTIONQA_DATASETS`, otherwise search upward for the repository root and fall back to `./datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e7b773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset root: D:\\CaptionQA\\data\n",
      "HR root: D:\\CaptionQA\\data\\360x\\360x_dataset_HR\n",
      "LR root: D:\\CaptionQA\\data\\360x\\360x_dataset_LR\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "import json\n",
    "import os\n",
    "\n",
    "def resolve_dataset_root() -> Path:\n",
    "    env_root = os.environ.get('CAPTIONQA_DATASETS')\n",
    "    if env_root:\n",
    "        return Path(env_root).expanduser().resolve()\n",
    "    cwd = Path.cwd()\n",
    "    for candidate in [cwd, *cwd.parents]:\n",
    "        if (candidate / 'pyproject.toml').exists() or (candidate / '.git').exists():\n",
    "            return (candidate / 'datasets').resolve()\n",
    "    return (cwd / 'datasets').resolve()\n",
    "\n",
    "DATASET_ROOT = resolve_dataset_root()\n",
    "print(f'Dataset root: {DATASET_ROOT}')\n",
    "HR_ROOT = DATASET_ROOT / '360x' / '360x_dataset_HR'\n",
    "LR_ROOT = DATASET_ROOT / '360x' / '360x_dataset_LR'\n",
    "print(f'HR root: {HR_ROOT}')\n",
    "print(f'LR root: {LR_ROOT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ad13d",
   "metadata": {},
   "source": [
    "## 2. Validate presence & summarize\n",
    "\n",
    "Run the next cell to verify the expected folder layout and capture a few file listings. The notebook handles missing data gracefully and prints next steps if the dataset is absent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e306c686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "High-resolution split -> D:\\CaptionQA\\data\\360x\\360x_dataset_HR\n",
      "Total entries: 5\n",
      " - .cache\n",
      " - .gitattributes\n",
      " - binocular\n",
      " - README.md\n",
      " - TAL_annotations\n",
      "\n",
      "Low-resolution split -> D:\\CaptionQA\\data\\360x\\360x_dataset_LR\n",
      "[missing] Not found. Download with: python -m captionqa.data.download 360x --output D:\\CaptionQA\\data\n"
     ]
    }
   ],
   "source": [
    "def describe_directory(root: Path, label: str, limit: int = 10):\n",
    "    print(f'\\n{label} -> {root}')\n",
    "    if not root.exists():\n",
    "        print('[missing] Not found. Download with: python -m captionqa.data.download 360x --output', DATASET_ROOT)\n",
    "        return\n",
    "    entries = sorted(root.iterdir())\n",
    "    print(f'Total entries: {len(entries)}')\n",
    "    for path in islice(entries, limit):\n",
    "        print(' -', path.name)\n",
    "    if len(entries) > limit:\n",
    "        print(' ...')\n",
    "\n",
    "describe_directory(HR_ROOT, 'High-resolution split')\n",
    "describe_directory(LR_ROOT, 'Low-resolution split')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0792ab4c",
   "metadata": {},
   "source": [
    "## 3. Sample metadata (optional)\n",
    "\n",
    "If JSON metadata files are available, the next cell attempts to load one sample to inspect structure. Adjust the glob pattern if the dataset uses a different naming scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "762e86b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previewing D:\\CaptionQA\\data\\360x\\360x_dataset_HR\\TAL_annotations\\019cc67f-512f-4b8a-96ef-81f806c86ce1.json\n",
      "{\n",
      "  \"file\": {\n",
      "    \"1\": {\n",
      "      \"fid\": \"1\",\n",
      "      \"fname\": \"360_panoramic.mp4\",\n",
      "      \"type\": 4,\n",
      "      \"loc\": 1,\n",
      "      \"src\": \"\"\n",
      "    }\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"1_1_1\": {\n",
      "      \"duration\": [\n",
      "        5.516,\n",
      "        7.3905\n",
      "      ],\n",
      "      \"action\": {\n",
      "        \"1\": \"sitting\"\n",
      "      }\n",
      "    },\n",
      "    \"1_2_2\": {\n",
      "      \"duration\": [\n",
      "        12.312,\n",
      "        17.47384\n",
      "      ],\n",
      "      \"action\": {\n",
      "        \"1\": \"drinking\"\n",
      "      }\n",
      "    },\n",
      "    \"1_2_3\": {\n",
      "      \"duration\": [\n",
      "        51.417,\n",
      "        56.46075\n",
      "      ],\n",
      "      \"action\": {\n",
      "        \"1\": \"drinking\"\n",
      "      }\n",
      "    },\n",
      "    \"1_2_4\": {\n",
      "      \"duration\": [\n",
      "        235.334,\n",
      "        237.98142\n",
      "      ],\n",
      "      \"action\": {\n",
      "        \"1\": \"drinking\"\n",
      "      }\n",
      "    },\n",
      "    \"1_3_5\": {\n",
      "      \"duration\": [\n",
      "        9.558,\n",
      "        116.33559\n",
      "      ],\n",
      "      \"action\": {\n",
      "        \"1\": \"speaking\"\n",
      "      }\n",
      "    },\n",
      "    \"1_3_6\": {\n",
      "      \"duration\": [\n",
      "        135.211,\n",
      "        167.50226\n",
      "      ],\n",
      "      \"action\": {\n",
      "        \"1\": \"speaking\"\n",
      "      }\n",
      "    },\n",
      "    \"1_3_7\": {\n",
      "      \"duration\": [\n",
      "        174.288,\n",
      "        232.31476\n",
      "      ],\n",
      "      \"action\": {\n",
      "        \"1\": \"speaking\"\n",
      "      }\n",
      "    },\n",
      "    \"1_3_8\": {\n",
      "      \"duration\": [\n",
      "        240.065,\n",
      "        271.08559\n",
      "      ],\n",
      "      \"action\": {\n",
      "        \"1\": \"speaking\"\n",
      "      }\n",
      "    },\n",
      "    \"1_3_9\": {\n",
      "      \"duration\": [\n",
      "        274.359,\n",
      "        324.34302\n",
      "      ],\n",
      "      \"action\": {\n",
      "        \"1\": \"speaking\"\n",
      "      }\n",
      "    },\n",
      "    \"1_4_10\": {\n",
      "      \"duration\": [\n",
      "        115.656,\n",
      "        313.96059\n",
      "      ],\n",
      "      \"action\": {\n",
      "        \"1\": \"operating phone\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "[skip] Root missing; nothing to load.\n"
     ]
    }
   ],
   "source": [
    "def load_sample_metadata(root: Path, suffix: str = '.json'):\n",
    "    if not root.exists():\n",
    "        print('[skip] Root missing; nothing to load.')\n",
    "        return\n",
    "    for path in sorted(root.rglob(f'*{suffix}')):\n",
    "        print(f'Previewing {path}')\n",
    "        try:\n",
    "            with path.open('r', encoding='utf-8') as handle:\n",
    "                snippet = json.load(handle)\n",
    "        except Exception as exc:\n",
    "            print('Failed to parse JSON:', exc)\n",
    "            return\n",
    "        print(json.dumps(snippet, indent=2)[:2000])\n",
    "        return\n",
    "    print('[skip] No files matching suffix found.')\n",
    "\n",
    "load_sample_metadata(HR_ROOT)\n",
    "load_sample_metadata(LR_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12c42cd",
   "metadata": {},
   "source": [
    "## 4. Next steps\n",
    "\n",
    "- Drill down into a representative panorama to inspect frame counts and available modalities (video, audio, annotations).\n",
    "- Compute dataset-level aggregates (duration, resolution, annotation coverage).\n",
    "- Integrate results into the main README or reporting pipeline once satisfied.\n",
    "\n",
    "> Tip: Run this notebook from the repo root with the `captionqa` uv environment activated to ensure imports resolve (`uv venv captionqa` / `./captionqa/Scripts/Activate.ps1`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "captionqa (3.10.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
